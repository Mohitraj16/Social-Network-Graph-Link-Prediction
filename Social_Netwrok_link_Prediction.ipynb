{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social Netwrok link Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NQobmebM4q0",
        "colab_type": "text"
      },
      "source": [
        "# **Social network Graph Link Prediction - Facebook challenge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IwPjbddNM1b",
        "colab_type": "text"
      },
      "source": [
        "**Problem statement:**\n",
        "Given a directed social graph, have to predict missing links to recommend users (Link Prediction in graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs9Mn3cVNVyi",
        "colab_type": "text"
      },
      "source": [
        "**Data Overview:**\n",
        "Taken data from facebook's recruting challenge on kaggle https://www.kaggle.com/c/FacebookRecruiting\n",
        "data contains two columns source and destination eac edge in graph - Data columns (total 2 columns):\n",
        "- source_node int64\n",
        "- destination_node int64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vVLhh2aNn1Z",
        "colab_type": "text"
      },
      "source": [
        "**Business objectives and constraints:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "No low-latency requirement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Probability of prediction is useful to recommend highest probability links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2u1SfSONIAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import csv\n",
        "import pandas as pd#pandas to create small dataframes \n",
        "import datetime #Convert to unix time\n",
        "import time #Convert to unix time\n",
        "# if numpy is not installed already : pip3 install numpy\n",
        "import numpy as np#Do aritmetic operations on arrays\n",
        "# matplotlib: used to plot graphs\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns#Plots\n",
        "from matplotlib import rcParams#Size of plots  \n",
        "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "# to install xgboost: pip3 install xgboost\n",
        "import xgboost as xgb\n",
        "\n",
        "import warnings\n",
        "import networkx as nx\n",
        "import pdb\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJqR1p5gOxGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading graph\n",
        "if not os.path.isfile('data/after_eda/train_woheader.csv'):\n",
        "    traincsv = pd.read_csv('data/train.csv')\n",
        "    print(traincsv[traincsv.isna().any(1)])\n",
        "    print(traincsv.info())\n",
        "    print(\"Number of diplicate entries: \",sum(traincsv.duplicated()))\n",
        "    traincsv.to_csv('data/after_eda/train_woheader.csv',header=False,index=False)\n",
        "    print(\"saved the graph into file\")\n",
        "else:\n",
        "    g=nx.read_edgelist('data/after_eda/train_woheader.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    print(nx.info(g))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHX_dIlVRfxp",
        "colab_type": "text"
      },
      "source": [
        "**Displaying a sub graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdGnBtMRaEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('train_woheader_sample.csv'):\n",
        "    pd.read_csv('data/train.csv', nrows=50).to_csv('train_woheader_sample.csv',header=False,index=False)\n",
        "    \n",
        "subgraph=nx.read_edgelist('train_woheader_sample.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "\n",
        "pos=nx.spring_layout(subgraph)\n",
        "nx.draw(subgraph,pos,node_color='#A0CBE2',edge_color='#00bb5e',width=1,edge_cmap=plt.cm.Blues,with_labels=True)\n",
        "plt.savefig(\"graph_sample.pdf\")\n",
        "print(nx.info(subgraph))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_fCTeCNRpyZ",
        "colab_type": "text"
      },
      "source": [
        "**1. Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWHfpC40RxP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No of Unique persons \n",
        "print(\"The number of unique persons\",len(g.nodes()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psEKJ0iHR5FY",
        "colab_type": "text"
      },
      "source": [
        "**1.1 No of followers for each person**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YuzUlAzR_zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indegree_dist = list(dict(g.in_degree()).values())\n",
        "indegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(indegree_dist)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of Followers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TBC1ksSGFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indegree_dist = list(dict(g.in_degree()).values())\n",
        "indegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(indegree_dist[0:1500000])\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of Followers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5QcBFhiSMpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.boxplot(indegree_dist)\n",
        "plt.ylabel('No Of Followers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8vWr4zKS2uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(indegree_dist,90+i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eB1yINvS6_R",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:**  99% of data having followers of 40 only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1YsA7_oTGsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(indegree_dist,99+(i/100)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kutKs6gTKkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11.7, 8.27)\n",
        "sns.distplot(indegree_dist, color='#16A085')\n",
        "plt.xlabel('PDF of Indegree')\n",
        "sns.despine()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0kRLHH9TPNY",
        "colab_type": "text"
      },
      "source": [
        "**1.2 No of people each person is following**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_S7ZECjTU5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outdegree_dist = list(dict(g.out_degree()).values())\n",
        "outdegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(outdegree_dist)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of people each person is following')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhaTXza0Tbia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indegree_dist = list(dict(g.in_degree()).values())\n",
        "indegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(outdegree_dist[0:1500000])\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of people each person is following')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKrxG_mKTiUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.boxplot(indegree_dist)\n",
        "plt.ylabel('No Of people each person is following')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2sHGavpTlsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(outdegree_dist,90+i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtKTP4-LUJ3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(outdegree_dist,99+(i/100)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DewFef2JUNnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11.7, 8.27)\n",
        "sns.distplot(outdegree_dist, color='#16A085')\n",
        "plt.xlabel('PDF of Outdegree')\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00wt9ywkURyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('No of persons those are not following anyone are' ,sum(np.array(outdegree_dist)==0),'and % is',\n",
        "                                sum(np.array(outdegree_dist)==0)*100/len(outdegree_dist) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyXR1u9jUVSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('No of persons having zero followers are' ,sum(np.array(indegree_dist)==0),'and % is',\n",
        "                                sum(np.array(indegree_dist)==0)*100/len(indegree_dist) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC5t60l_Uc6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count=0\n",
        "for i in g.nodes():\n",
        "    if len(list(g.predecessors(i)))==0 :\n",
        "        if len(list(g.successors(i)))==0:\n",
        "            count+=1\n",
        "print('No of persons those are not not following anyone and also not having any followers are',count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1YFApe-UhnS",
        "colab_type": "text"
      },
      "source": [
        "**1.3 Both followers + following**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAucET8vUkzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "dict_in = dict(g.in_degree())\n",
        "dict_out = dict(g.out_degree())\n",
        "d = Counter(dict_in) + Counter(dict_out)\n",
        "in_out_degree = np.array(list(d.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mg8M1oqUqJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out_degree_sort = sorted(in_out_degree)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(in_out_degree_sort)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of people each person is following + followers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDL_fgo3Uszp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_out_degree_sort = sorted(in_out_degree)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(in_out_degree_sort[0:1500000])\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of people each person is following + followers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aou00QAYUwFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(in_out_degree_sort,90+i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANAPHpdkUzQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(in_out_degree_sort,99+(i/100)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FW4J6zHU27a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Min of no of followers + following is',in_out_degree.min())\n",
        "print(np.sum(in_out_degree==in_out_degree.min()),' persons having minimum no of followers + following')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m88-Cfw8U5yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Max of no of followers + following is',in_out_degree.max())\n",
        "print(np.sum(in_out_degree==in_out_degree.max()),' persons having maximum no of followers + following')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TafXN7T2U8bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('No of persons having followers + following less than 10 are',np.sum(in_out_degree<10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ccFiyfXU_-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('No of weakly connected components',len(list(nx.weakly_connected_components(g))))\n",
        "count=0\n",
        "for i in list(nx.weakly_connected_components(g)):\n",
        "    if len(i)==2:\n",
        "        count+=1\n",
        "print('weakly connected components wit 2 nodes',count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCDJDRz_VE0s",
        "colab_type": "text"
      },
      "source": [
        "**2. Posing a problem as classification problem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVx71oLbVL9B",
        "colab_type": "text"
      },
      "source": [
        "**2.1 Generating some edges which are not present in graph for supervised learning**\n",
        "\n",
        "Generated Bad links from graph which are not in graph and whose shortest path is greater than 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVK_otB-VH9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "###generating bad edges from given graph\n",
        "import random\n",
        "if not os.path.isfile('data/after_eda/missing_edges_final.p'):\n",
        "    #getting all set of edges\n",
        "    r = csv.reader(open('data/after_eda/train_woheader.csv','r'))\n",
        "    edges = dict()\n",
        "    for edge in r:\n",
        "        edges[(edge[0], edge[1])] = 1\n",
        "        \n",
        "        \n",
        "    missing_edges = set([])\n",
        "    while (len(missing_edges)<9437519):\n",
        "        a=random.randint(1, 1862220)\n",
        "        b=random.randint(1, 1862220)\n",
        "        tmp = edges.get((a,b),-1)\n",
        "        if tmp == -1 and a!=b:\n",
        "            try:\n",
        "                if nx.shortest_path_length(g,source=a,target=b) > 2: \n",
        "\n",
        "                    missing_edges.add((a,b))\n",
        "                else:\n",
        "                    continue  \n",
        "            except:  \n",
        "                    missing_edges.add((a,b))              \n",
        "        else:\n",
        "            continue\n",
        "    pickle.dump(missing_edges,open('data/after_eda/missing_edges_final.p','wb'))\n",
        "else:\n",
        "    missing_edges = pickle.load(open('data/after_eda/missing_edges_final.p','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqF8spBVcrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(missing_edges)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Bvg1wmVluY",
        "colab_type": "text"
      },
      "source": [
        "**2.2 Training and Test data split:**\n",
        "\n",
        "Removed edges from Graph and used as test data and after removing used that graph for creating features for Train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUBvAyz_VyRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "if (not os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and (not os.path.isfile('data/after_eda/test_pos_after_eda.csv')):\n",
        "    #reading total data df\n",
        "    df_pos = pd.read_csv('data/train.csv')\n",
        "    df_neg = pd.DataFrame(list(missing_edges), columns=['source_node', 'destination_node'])\n",
        "    \n",
        "    print(\"Number of nodes in the graph with edges\", df_pos.shape[0])\n",
        "    print(\"Number of nodes in the graph without edges\", df_neg.shape[0])\n",
        "    \n",
        "    #Trian test split \n",
        "    #Spiltted data into 80-20 \n",
        "    #positive links and negative links seperatly because we need positive training data only for creating graph \n",
        "    #and for feature generation\n",
        "    X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(df_pos,np.ones(len(df_pos)),test_size=0.2, random_state=9)\n",
        "    X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(df_neg,np.zeros(len(df_neg)),test_size=0.2, random_state=9)\n",
        "    \n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0],\"=\",y_train_pos.shape[0])\n",
        "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0],\"=\", y_train_neg.shape[0])\n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0],\"=\",y_test_pos.shape[0])\n",
        "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0],\"=\",y_test_neg.shape[0])\n",
        "\n",
        "    #removing header and saving\n",
        "    X_train_pos.to_csv('data/after_eda/train_pos_after_eda.csv',header=False, index=False)\n",
        "    X_test_pos.to_csv('data/after_eda/test_pos_after_eda.csv',header=False, index=False)\n",
        "    X_train_neg.to_csv('data/after_eda/train_neg_after_eda.csv',header=False, index=False)\n",
        "    X_test_neg.to_csv('data/after_eda/test_neg_after_eda.csv',header=False, index=False)\n",
        "else:\n",
        "    #Graph from Traing data only \n",
        "    del missing_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2J8ymEDV2RT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and (os.path.isfile('data/after_eda/test_pos_after_eda.csv')):        \n",
        "    train_graph=nx.read_edgelist('data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    test_graph=nx.read_edgelist('data/after_eda/test_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    print(nx.info(train_graph))\n",
        "    print(nx.info(test_graph))\n",
        "\n",
        "    # finding the unique nodes in the both train and test graphs\n",
        "    train_nodes_pos = set(train_graph.nodes())\n",
        "    test_nodes_pos = set(test_graph.nodes())\n",
        "\n",
        "    trY_teY = len(train_nodes_pos.intersection(test_nodes_pos))\n",
        "    trY_teN = len(train_nodes_pos - test_nodes_pos)\n",
        "    teY_trN = len(test_nodes_pos - train_nodes_pos)\n",
        "\n",
        "    print('no of people common in train and test -- ',trY_teY)\n",
        "    print('no of people present in train but not present in test -- ',trY_teN)\n",
        "\n",
        "    print('no of people present in test but not present in train -- ',teY_trN)\n",
        "    print(' % of people not there in Train but exist in Test in total Test data are {} %'.format(teY_trN/len(test_nodes_pos)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByNU5Yv9V93i",
        "colab_type": "text"
      },
      "source": [
        "Note- Data has a issue of Cold Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJKD05eUV-oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#final train and test data sets\n",
        "if (not os.path.isfile('data/after_eda/train_after_eda.csv')) and \\\n",
        "(not os.path.isfile('data/after_eda/test_after_eda.csv')) and \\\n",
        "(not os.path.isfile('data/train_y.csv')) and \\\n",
        "(not os.path.isfile('data/test_y.csv')) and \\\n",
        "(os.path.isfile('data/after_eda/train_pos_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/after_eda/test_pos_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/after_eda/train_neg_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/after_eda/test_neg_after_eda.csv')):\n",
        "    \n",
        "    X_train_pos = pd.read_csv('data/after_eda/train_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_test_pos = pd.read_csv('data/after_eda/test_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_train_neg = pd.read_csv('data/after_eda/train_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_test_neg = pd.read_csv('data/after_eda/test_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "\n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0])\n",
        "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0])\n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0])\n",
        "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0])\n",
        "\n",
        "    X_train = X_train_pos.append(X_train_neg,ignore_index=True)\n",
        "    y_train = np.concatenate((y_train_pos,y_train_neg))\n",
        "    X_test = X_test_pos.append(X_test_neg,ignore_index=True)\n",
        "    y_test = np.concatenate((y_test_pos,y_test_neg)) \n",
        "    \n",
        "    X_train.to_csv('data/after_eda/train_after_eda.csv',header=False,index=False)\n",
        "    X_test.to_csv('data/after_eda/test_after_eda.csv',header=False,index=False)\n",
        "    pd.DataFrame(y_train.astype(int)).to_csv('data/train_y.csv',header=False,index=False)\n",
        "    pd.DataFrame(y_test.astype(int)).to_csv('data/test_y.csv',header=False,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2mTHz6WQTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Data points in train data\",X_train.shape)\n",
        "print(\"Data points in test data\",X_test.shape)\n",
        "print(\"Shape of traget variable in train\",y_train.shape)\n",
        "print(\"Shape of traget variable in test\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEtxIsw7WgJ5",
        "colab_type": "text"
      },
      "source": [
        "# 3. **Featurization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmhJkQnHWshc",
        "colab_type": "text"
      },
      "source": [
        "**3.1. Reading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJIwCKLXdZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import HDFStore,DataFrame\n",
        "from pandas import read_hdf\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "import gc\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8ZLnc7jXhuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.isfile('data/after_eda/train_pos_after_eda.csv'):\n",
        "    train_graph=nx.read_edgelist('data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    print(nx.info(train_graph))\n",
        "else:\n",
        "    print(\"please run the FB_EDA.ipynb or download the files from drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5-wMT5SXo8i",
        "colab_type": "text"
      },
      "source": [
        "**3.2 Similarity measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vTQGfKzYJPM",
        "colab_type": "text"
      },
      "source": [
        "**3.2.1. Jaccard Distance:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7pmpah8YVHo",
        "colab_type": "text"
      },
      "source": [
        "#                                       J = |X∩Y|/|X∪Y|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FFe1f6bXn94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for followees\n",
        "def jaccard_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
        "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
        "    except:\n",
        "        return 0\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvZbeMAZUxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one test case\n",
        "print(jaccard_for_followees(273084,1505602))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwyG38HdZXfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#node 1635354 not in graph \n",
        "print(jaccard_for_followees(273084,1505602))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6CF4iE5Zct5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for followers\n",
        "def jaccard_for_followers(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
        "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_1oV-TvZf9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(jaccard_for_followers(273084,470294))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXVL0NsbZjTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#node 1635354 not in graph \n",
        "print(jaccard_for_followees(669354,1635354))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK_A72rfZpyI",
        "colab_type": "text"
      },
      "source": [
        "**3.2.2 Cosine distance**\n",
        "\n",
        "#                        CosineDistance=|X∩Y|/|X|⋅|Y|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af9zvATHZ9JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for followees\n",
        "def cosine_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
        "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC2n2oNKaAV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cosine_for_followees(273084,1505602))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oGJG-ZaaDRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cosine_for_followees(273084,1635354))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0VGIIeoaGN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_for_followers(a,b):\n",
        "    try:\n",
        "        \n",
        "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
        "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjKki1g4aJ6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cosine_for_followers(2,470294))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rptjxiO1aMGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cosine_for_followers(669354,1635354))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClxgTQiTaO7d",
        "colab_type": "text"
      },
      "source": [
        "**3.3 Ranking Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIaL88z3aqUC",
        "colab_type": "text"
      },
      "source": [
        "**3.3.1 Page Ranking**\n",
        "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i0210C0a4be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/page_rank.p'):\n",
        "    pr = nx.pagerank(train_graph, alpha=0.85)\n",
        "    pickle.dump(pr,open('data/fea_sample/page_rank.p','wb'))\n",
        "else:\n",
        "    pr = pickle.load(open('data/fea_sample/page_rank.p','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDdWOwOna7n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('min',pr[min(pr, key=pr.get)])\n",
        "print('max',pr[max(pr, key=pr.get)])\n",
        "print('mean',float(sum(pr.values())) / len(pr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw-Clq_Ja-_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for imputing to nodes which are not there in Train data\n",
        "mean_pr = float(sum(pr.values())) / len(pr)\n",
        "print(mean_pr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yslVjvdFbDMx",
        "colab_type": "text"
      },
      "source": [
        "**3.4 Other Graph Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQXiWUSbHYK",
        "colab_type": "text"
      },
      "source": [
        "**3.4.1 Shortest path:**\n",
        "Getting Shortest path between twoo nodes, if nodes have direct path i.e directly connected then we are removing that edge and calculating path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRIgSuEQbRRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if has direct edge then deleting that edge and calculating shortest path\n",
        "def compute_shortest_path_length(a,b):\n",
        "    p=-1\n",
        "    try:\n",
        "        if train_graph.has_edge(a,b):\n",
        "            train_graph.remove_edge(a,b)\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "            train_graph.add_edge(a,b)\n",
        "        else:\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "        return p\n",
        "    except:\n",
        "        return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cOkzy_4bU5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "compute_shortest_path_length(77697, 826021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7CZv67wbX5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "compute_shortest_path_length(669354,1635354)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4qQ8KYEbikB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNGKRMnEbbon",
        "colab_type": "text"
      },
      "source": [
        "**3.4.2 Checking for same community**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HptBr2EibjYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting weekly connected edges from graph \n",
        "wcc=list(nx.weakly_connected_components(train_graph))\n",
        "def belongs_to_same_wcc(a,b):\n",
        "    index = []\n",
        "    if train_graph.has_edge(b,a):\n",
        "        return 1\n",
        "    if train_graph.has_edge(a,b):\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if (b in index):\n",
        "                train_graph.remove_edge(a,b)\n",
        "                if compute_shortest_path_length(a,b)==-1:\n",
        "                    train_graph.add_edge(a,b)\n",
        "                    return 0\n",
        "                else:\n",
        "                    train_graph.add_edge(a,b)\n",
        "                    return 1\n",
        "            else:\n",
        "                return 0\n",
        "    else:\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if(b in index):\n",
        "                return 1\n",
        "            else:\n",
        "                return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tRZRkgAbn98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "belongs_to_same_wcc(861, 1659750)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qE_djU2bqYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "belongs_to_same_wcc(669354,1635354)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX8uJ563bxmV",
        "colab_type": "text"
      },
      "source": [
        "**3.4.3 Adamic/Adar Index:**\n",
        "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices.\n",
        "\n",
        "                   A(x,y)=∑u∈N(x)∩N(y)1log(|N(u)|)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSqBZ1qycBdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adar index\n",
        "def calc_adar_in(a,b):\n",
        "    sum=0\n",
        "    try:\n",
        "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
        "        if len(n)!=0:\n",
        "            for i in n:\n",
        "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
        "            return sum\n",
        "        else:\n",
        "            return 0\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMRHEcYJcE7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calc_adar_in(1,189226)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Cu59sfcIKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calc_adar_in(669354,1635354)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjz_9BTdcMuv",
        "colab_type": "text"
      },
      "source": [
        "**3.4.4 Is persion was following back:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1J9umjycUcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def follows_back(a,b):\n",
        "    if train_graph.has_edge(b,a):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvVl3xoncVZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "follows_back(1,189226)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxxtXhsRcX8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "follows_back(669354,1635354)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utfW67dzcdsZ",
        "colab_type": "text"
      },
      "source": [
        "**3.4.5 Katz Centrality:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whif2bzBcnoD",
        "colab_type": "text"
      },
      "source": [
        "Katz centrality computes the centrality for a node based on the centrality of its neighbors. It is a generalization of the eigenvector centrality. The Katz centrality for node i is\n",
        "\n",
        "xi=α∑jAijxj+β, \n",
        "where A is the adjacency matrix of the graph G with eigenvalues\n",
        "λ \n",
        ".\n",
        "\n",
        "The parameter\n",
        "β \n",
        "controls the initial centrality and\n",
        "\n",
        "α<1λmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYwVF9ZXcvMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/katz.p'):\n",
        "    katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
        "    pickle.dump(katz,open('data/fea_sample/katz.p','wb'))\n",
        "else:\n",
        "    katz = pickle.load(open('data/fea_sample/katz.p','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1ubInTpcx0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('min',katz[min(katz, key=katz.get)])\n",
        "print('max',katz[max(katz, key=katz.get)])\n",
        "print('mean',float(sum(katz.values())) / len(katz))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7RBZ1r8c0nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_katz = float(sum(katz.values())) / len(katz)\n",
        "print(mean_katz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk1sHm9Ec4rY",
        "colab_type": "text"
      },
      "source": [
        "**3.4.6 Hits Score**\n",
        "\n",
        "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_4gcztSdGn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/hits.p'):\n",
        "    hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
        "    pickle.dump(hits,open('data/fea_sample/hits.p','wb'))\n",
        "else:\n",
        "    hits = pickle.load(open('data/fea_sample/hits.p','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swdjXRKxdKeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
        "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
        "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddoPhQydQfd",
        "colab_type": "text"
      },
      "source": [
        "**4. Featurization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQMi3r_zdUOq",
        "colab_type": "text"
      },
      "source": [
        "**4.1 Reading a sample of Data from both train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zNddRYvdd2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "if os.path.isfile('data/after_eda/train_after_eda.csv'):\n",
        "    filename = \"data/after_eda/train_after_eda.csv\"\n",
        "    # you uncomment this line, if you dont know the lentgh of the file name\n",
        "    # here we have hardcoded the number of lines as 15100030\n",
        "    # n_train = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
        "    n_train =  15100028\n",
        "    s = 100000 #desired sample size\n",
        "    skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))\n",
        "    #https://stackoverflow.com/a/22259008/4084039"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV_5PTIpdf-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.isfile('data/after_eda/train_after_eda.csv'):\n",
        "    filename = \"data/after_eda/test_after_eda.csv\"\n",
        "    # you uncomment this line, if you dont know the lentgh of the file name\n",
        "    # here we have hardcoded the number of lines as 3775008\n",
        "    # n_test = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
        "    n_test = 3775006\n",
        "    s = 50000 #desired sample size\n",
        "    skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))\n",
        "    #https://stackoverflow.com/a/22259008/4084039"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbrdicAdi6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of rows in the train data file:\", n_train)\n",
        "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
        "print(\"Number of rows in the test data file:\", n_test)\n",
        "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8FYPp66dlbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final_train = pd.read_csv('data/after_eda/train_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
        "df_final_train['indicator_link'] = pd.read_csv('data/train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
        "print(\"Our train matrix size \",df_final_train.shape)\n",
        "df_final_train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE6GPE4Vdokp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final_test = pd.read_csv('data/after_eda/test_after_eda.csv', skiprows=skip_test, names=['source_node', 'destination_node'])\n",
        "df_final_test['indicator_link'] = pd.read_csv('data/test_y.csv', skiprows=skip_test, names=['indicator_link'])\n",
        "print(\"Our test matrix size \",df_final_test.shape)\n",
        "df_final_test.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1jOExxRdsAD",
        "colab_type": "text"
      },
      "source": [
        "**4.2 Adding a set of features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY9GomzId0N5",
        "colab_type": "text"
      },
      "source": [
        "I will create each of these features for both train and test data points\n",
        "\n",
        "1.jaccard_followers\n",
        "2.jaccard_followees\n",
        "3.cosine_followers\n",
        "4.cosine_followees\n",
        "5.num_followers_s\n",
        "6.num_followees_s\n",
        "7.num_followers_d\n",
        "8.num_followees_d\n",
        "9.inter_followers\n",
        "10.inter_followees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSsgbE10eHG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage1.h5'):\n",
        "    #mapping jaccrd followers to train and test data\n",
        "    df_final_train['jaccard_followers'] = df_final_train.apply(lambda row:\n",
        "                                            jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "    df_final_test['jaccard_followers'] = df_final_test.apply(lambda row:\n",
        "                                            jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    #mapping jaccrd followees to train and test data\n",
        "    df_final_train['jaccard_followees'] = df_final_train.apply(lambda row:\n",
        "                                            jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "    df_final_test['jaccard_followees'] = df_final_test.apply(lambda row:\n",
        "                                            jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "    \n",
        "\n",
        "        #mapping jaccrd followers to train and test data\n",
        "    df_final_train['cosine_followers'] = df_final_train.apply(lambda row:\n",
        "                                            cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "    df_final_test['cosine_followers'] = df_final_test.apply(lambda row:\n",
        "                                            cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    #mapping jaccrd followees to train and test data\n",
        "    df_final_train['cosine_followees'] = df_final_train.apply(lambda row:\n",
        "                                            cosine_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "    df_final_test['cosine_followees'] = df_final_test.apply(lambda row:\n",
        "                                            cosine_for_followees(row['source_node'],row['destination_node']),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ-mU2PJeMLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_features_stage1(df_final):\n",
        "    #calculating no of followers followees for source and destination\n",
        "    #calculating intersection of followers and followees for source and destination\n",
        "    num_followers_s=[]\n",
        "    num_followees_s=[]\n",
        "    num_followers_d=[]\n",
        "    num_followees_d=[]\n",
        "    inter_followers=[]\n",
        "    inter_followees=[]\n",
        "    for i,row in df_final.iterrows():\n",
        "        try:\n",
        "            s1=set(train_graph.predecessors(row['source_node']))\n",
        "            s2=set(train_graph.successors(row['source_node']))\n",
        "        except:\n",
        "            s1 = set()\n",
        "            s2 = set()\n",
        "        try:\n",
        "            d1=set(train_graph.predecessors(row['destination_node']))\n",
        "            d2=set(train_graph.successors(row['destination_node']))\n",
        "        except:\n",
        "            d1 = set()\n",
        "            d2 = set()\n",
        "        num_followers_s.append(len(s1))\n",
        "        num_followees_s.append(len(s2))\n",
        "\n",
        "        num_followers_d.append(len(d1))\n",
        "        num_followees_d.append(len(d2))\n",
        "\n",
        "        inter_followers.append(len(s1.intersection(d1)))\n",
        "        inter_followees.append(len(s2.intersection(d2)))\n",
        "    \n",
        "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcJCGWEeQHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage1.h5'):\n",
        "    df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
        "    df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
        "    df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)\n",
        "    \n",
        "    df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
        "    df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
        "    df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)\n",
        "    \n",
        "    hdf = HDFStore('data/fea_sample/storage_sample_stage1.h5')\n",
        "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "    hdf.close()\n",
        "else:\n",
        "    df_final_train = read_hdf('data/fea_sample/storage_sample_stage1.h5', 'train_df',mode='r')\n",
        "    df_final_test = read_hdf('data/fea_sample/storage_sample_stage1.h5', 'test_df',mode='r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orIk5qjqedPZ",
        "colab_type": "text"
      },
      "source": [
        "**4.3 Adding new set of features**\n",
        "I will create each of these features for both train and test data points\n",
        "\n",
        "1. adar index\n",
        "\n",
        "2. is following back\n",
        "\n",
        "3. belongs to same weakly connect components\n",
        "\n",
        "4. shortest path between source and destination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HwxzmR1e19M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage2.h5'):\n",
        "    #mapping adar index on train\n",
        "    df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
        "    #mapping adar index on test\n",
        "    df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    #--------------------------------------------------------------------------------------------------------\n",
        "    #mapping followback or not on train\n",
        "    df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    #mapping followback or not on test\n",
        "    df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    #--------------------------------------------------------------------------------------------------------\n",
        "    #mapping same component of wcc or not on train\n",
        "    df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    ##mapping same component of wcc or not on train\n",
        "    df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
        "    \n",
        "    #--------------------------------------------------------------------------------------------------------\n",
        "    #mapping shortest path on train \n",
        "    df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
        "    #mapping shortest path on test\n",
        "    df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "    hdf = HDFStore('data/fea_sample/storage_sample_stage2.h5')\n",
        "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "    hdf.close()\n",
        "else:\n",
        "    df_final_train = read_hdf('data/fea_sample/storage_sample_stage2.h5', 'train_df',mode='r')\n",
        "    df_final_test = read_hdf('data/fea_sample/storage_sample_stage2.h5', 'test_df',mode='r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiwhDVZue-Rl",
        "colab_type": "text"
      },
      "source": [
        "**4.4 Adding new set of features**\n",
        "\n",
        "I will create these each of these features for both train and test data points\n",
        "\n",
        "1. Weight Features\n",
        "\n",
        "- weight of incoming edges\n",
        "\n",
        "- weight of outgoing edges\n",
        "- weight of incoming edges + weight of outgoing edges\n",
        "- weight of incoming edges * weight of outgoing edges\n",
        "- 2*weight of incoming edges + weight of outgoing edges\n",
        "- weight of incoming edges + 2*weight of outgoing edges\n",
        "2. Page Ranking of source\n",
        "3. Page Ranking of dest\n",
        "4. katz of source\n",
        "5. katz of dest\n",
        "6. hubs of source\n",
        "7. hubs of dest\n",
        "8. authorities_s of source\n",
        "9. authorities_s of dest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dYifXdrf7ig",
        "colab_type": "text"
      },
      "source": [
        "Weight Features\n",
        "In order to determine the similarity of nodes, an edge weight value was calculated between nodes. Edge weight decreases as the neighbor count goes up. Intuitively, consider one million people following a celebrity on a social network then chances are most of them never met each other or the celebrity. On the other hand, if a user has 30 contacts in his/her social network, the chances are higher that many of them know each other. credit - Graph-based Features for Supervised Link Prediction William Cukierski, Benjamin Hamner, Bo Yang\n",
        "\n",
        "W=1/√(1+|X|)\n",
        "\n",
        "it is directed graph so calculated Weighted in and Weighted out differently"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ONptr_gSft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#weight for source and destination of each link\n",
        "Weight_in = {}\n",
        "Weight_out = {}\n",
        "for i in  tqdm(train_graph.nodes()):\n",
        "    s1=set(train_graph.predecessors(i))\n",
        "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
        "    Weight_in[i]=w_in\n",
        "    \n",
        "    s2=set(train_graph.successors(i))\n",
        "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
        "    Weight_out[i]=w_out\n",
        "    \n",
        "#for imputing with mean\n",
        "mean_weight_in = np.mean(list(Weight_in.values()))\n",
        "mean_weight_out = np.mean(list(Weight_out.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGGqzj_gVBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage3.h5'):\n",
        "    #mapping to pandas train\n",
        "    df_final_train['weight_in'] = df_final_train.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
        "    df_final_train['weight_out'] = df_final_train.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
        "\n",
        "    #mapping to pandas test\n",
        "    df_final_test['weight_in'] = df_final_test.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
        "    df_final_test['weight_out'] = df_final_test.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
        "\n",
        "\n",
        "    #some features engineerings on the in and out weights\n",
        "    df_final_train['weight_f1'] = df_final_train.weight_in + df_final_train.weight_out\n",
        "    df_final_train['weight_f2'] = df_final_train.weight_in * df_final_train.weight_out\n",
        "    df_final_train['weight_f3'] = (2*df_final_train.weight_in + 1*df_final_train.weight_out)\n",
        "    df_final_train['weight_f4'] = (1*df_final_train.weight_in + 2*df_final_train.weight_out)\n",
        "\n",
        "    #some features engineerings on the in and out weights\n",
        "    df_final_test['weight_f1'] = df_final_test.weight_in + df_final_test.weight_out\n",
        "    df_final_test['weight_f2'] = df_final_test.weight_in * df_final_test.weight_out\n",
        "    df_final_test['weight_f3'] = (2*df_final_test.weight_in + 1*df_final_test.weight_out)\n",
        "    df_final_test['weight_f4'] = (1*df_final_test.weight_in + 2*df_final_test.weight_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oA3axDggXoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage3.h5'):\n",
        "    \n",
        "    #page rank for source and destination in Train and Test\n",
        "    #if anything not there in train graph then adding mean page rank \n",
        "    df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "    df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "\n",
        "    df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "    df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "    #================================================================================\n",
        "\n",
        "    #Katz centrality score for source and destination in Train and test\n",
        "    #if anything not there in train graph then adding mean katz score\n",
        "    df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "    df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "\n",
        "    df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "    df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "    #================================================================================\n",
        "\n",
        "    #Hits algorithm score for source and destination in Train and test\n",
        "    #if anything not there in train graph then adding 0\n",
        "    df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
        "    df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
        "\n",
        "    df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
        "    df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
        "    #================================================================================\n",
        "\n",
        "    #Hits algorithm score for source and destination in Train and Test\n",
        "    #if anything not there in train graph then adding 0\n",
        "    df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
        "    df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
        "\n",
        "    df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
        "    df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))\n",
        "    #================================================================================\n",
        "\n",
        "    hdf = HDFStore('data/fea_sample/storage_sample_stage3.h5')\n",
        "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "    hdf.close()\n",
        "else:\n",
        "    df_final_train = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'train_df',mode='r')\n",
        "    df_final_test = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'test_df',mode='r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDOiKyLOgdW7",
        "colab_type": "text"
      },
      "source": [
        "**4.5 Adding new set of features**\n",
        "\n",
        "I will create each of these features for both train and test data points\n",
        "\n",
        "SVD features for both source and destination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCsB40fYglX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svd(x, S):\n",
        "    try:\n",
        "        z = sadj_dict[x]\n",
        "        return S[z]\n",
        "    except:\n",
        "        return [0,0,0,0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0e43PSfgoIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for svd features to get feature vector creating a dict node val and inedx in svd vector\n",
        "sadj_col = sorted(train_graph.nodes())\n",
        "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZosZmLOUgq1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adj = nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldpUpPD7gt-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "U, s, V = svds(Adj, k = 6)\n",
        "print('Adjacency matrix Shape',Adj.shape)\n",
        "print('U Shape',U.shape)\n",
        "print('V Shape',V.shape)\n",
        "print('s Shape',s.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNzqajekgwrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('data/fea_sample/storage_sample_stage4.h5'):\n",
        "    #===================================================================================================\n",
        "    \n",
        "    df_final_train[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
        "    df_final_train.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
        "    \n",
        "    df_final_train[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
        "    df_final_train.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
        "    #===================================================================================================\n",
        "    \n",
        "    df_final_train[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
        "    df_final_train.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
        "\n",
        "    df_final_train[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
        "    df_final_train.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
        "    #===================================================================================================\n",
        "    \n",
        "    df_final_test[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
        "    df_final_test.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
        "    \n",
        "    df_final_test[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
        "    df_final_test.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
        "\n",
        "    #===================================================================================================\n",
        "    \n",
        "    df_final_test[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
        "    df_final_test.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
        "\n",
        "    df_final_test[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
        "    df_final_test.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
        "    #===================================================================================================\n",
        "\n",
        "    hdf = HDFStore('data/fea_sample/storage_sample_stage4.h5')\n",
        "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "    hdf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjdCTvbg5D3",
        "colab_type": "text"
      },
      "source": [
        "**5.Model Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZkfnpcg3Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oL9tE8ehCOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading\n",
        "from pandas import read_hdf\n",
        "df_final_train = read_hdf('data/fea_sample/storage_sample_stage4.h5', 'train_df',mode='r')\n",
        "df_final_test = read_hdf('data/fea_sample/storage_sample_stage4.h5', 'test_df',mode='r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0bI1MhWhHJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-3bDvHmhKEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = df_final_train.indicator_link\n",
        "y_test = df_final_test.indicator_link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhuBHJuLhK4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final_train.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)\n",
        "df_final_test.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wggKgl5ahNBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [10,50,100,250,450]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "for i in estimators:\n",
        "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=52, min_samples_split=120,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=i, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
        "    clf.fit(df_final_train,y_train)\n",
        "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
        "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
        "    test_scores.append(test_sc)\n",
        "    train_scores.append(train_sc)\n",
        "    print('Estimators = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
        "plt.plot(estimators,train_scores,label='Train Score')\n",
        "plt.plot(estimators,test_scores,label='Test Score')\n",
        "plt.xlabel('Estimators')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Estimators vs score at depth of 5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHcSnVvhRpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depths = [3,9,11,15,20,35,50,70,130]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "for i in depths:\n",
        "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=i, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=52, min_samples_split=120,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=115, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
        "    clf.fit(df_final_train,y_train)\n",
        "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
        "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
        "    test_scores.append(test_sc)\n",
        "    train_scores.append(train_sc)\n",
        "    print('depth = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
        "plt.plot(depths,train_scores,label='Train Score')\n",
        "plt.plot(depths,test_scores,label='Test Score')\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Depth vs score at depth of 5 at estimators = 115')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXvTZZUEhVZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform\n",
        "\n",
        "param_dist = {\"n_estimators\":sp_randint(105,125),\n",
        "              \"max_depth\": sp_randint(10,15),\n",
        "              \"min_samples_split\": sp_randint(110,190),\n",
        "              \"min_samples_leaf\": sp_randint(25,65)}\n",
        "\n",
        "clf = RandomForestClassifier(random_state=25,n_jobs=-1)\n",
        "\n",
        "rf_random = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=5,cv=10,scoring='f1',random_state=25)\n",
        "\n",
        "rf_random.fit(df_final_train,y_train)\n",
        "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
        "print('mean train scores',rf_random.cv_results_['mean_train_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kep8NVouhaV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(rf_random.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yunj7osxhd36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=28, min_samples_split=111,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=121, n_jobs=-1,\n",
        "            oob_score=False, random_state=25, verbose=0, warm_start=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdHhA-hJhhiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(df_final_train,y_train)\n",
        "y_train_pred = clf.predict(df_final_train)\n",
        "y_test_pred = clf.predict(df_final_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTSYKfjVhhds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
        "print('Test f1 score',f1_score(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-A87_IchlIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(test_y, predict_y):\n",
        "    C = confusion_matrix(test_y, predict_y)\n",
        "    \n",
        "    A =(((C.T)/(C.sum(axis=1))).T)\n",
        "    \n",
        "    B =(C/C.sum(axis=0))\n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    labels = [0,1]\n",
        "    # representing A in heatmap format\n",
        "    cmap=sns.light_palette(\"blue\")\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Precision matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    # representing B in heatmap format\n",
        "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Recall matrix\")\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFa96eZhho_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train confusion_matrix')\n",
        "plot_confusion_matrix(y_train,y_train_pred)\n",
        "print('Test confusion_matrix')\n",
        "plot_confusion_matrix(y_test,y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt9tWMQXhrYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr,tpr,ths = roc_curve(y_test,y_test_pred)\n",
        "auc_sc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='navy',label='ROC curve (area = %0.2f)' % auc_sc)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic with test data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPYXI8_ihwEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = df_final_train.columns\n",
        "importances = clf.feature_importances_\n",
        "indices = (np.argsort(importances))[-25:]\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}